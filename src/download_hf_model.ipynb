{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c876f22f-be54-47a3-ba3d-d749e9b3c3e9",
   "metadata": {},
   "source": [
    "## Download model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6b9f36-63fd-47c2-a3ad-1383248eac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12ddbeeaa5445d5a78b0b886403c015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984115447530461e995cd18cd5de0768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd007765ba474fb79c84aaae7ce89a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b010ee92254f26b6dd127543dd8452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478d6fdd279a4c2abd09b5ac3ada533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81c9483942f477b89ec8a6e6efdfed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06da41d0f6646b1a9bffeb415c68854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac03109d427403eaf423dc3a6e6acb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('SmolLM2-135M-Instruct/tokenizer_config.json',\n",
       " 'SmolLM2-135M-Instruct/special_tokens_map.json',\n",
       " 'SmolLM2-135M-Instruct/vocab.json',\n",
       " 'SmolLM2-135M-Instruct/merges.txt',\n",
       " 'SmolLM2-135M-Instruct/added_tokens.json',\n",
       " 'SmolLM2-135M-Instruct/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Define Model Name and MLflow Tracking URI\n",
    "HF_MODEL_NAME = 'HuggingFaceTB/SmolLM2-135M-Instruct'  # Model from Hugging Face\n",
    "MLFLOW_TRACKING_URI = 'http://localhost:5000'  # Adjust if MLflow is running elsewhere\n",
    "\n",
    "# Set MLflow Tracking Server\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Load Model and Tokenizer from Hugging Face\n",
    "model = AutoModelForCausalLM.from_pretrained(HF_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)\n",
    "\n",
    "# Save Model Locally Before Logging to MLflow\n",
    "MODEL_DIR = \"SmolLM2-135M-Instruct\"\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392eb02-8a3b-4a2f-ac73-a310b084f8ce",
   "metadata": {},
   "source": [
    "## Save model onto MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74dda742-7fd7-4e02-8d4c-1f2486887ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_HTTP_REQUEST_MAX_SIZE\"] = str(256 * 1024 * 1024)  # 256MB\n",
    "os.environ[\"MLFLOW_UPLOAD_BUFFER_SIZE\"] = str(128 * 1024 * 1024)  # 128MB\n",
    "os.environ[\"MLFLOW_MAX_ARTIFACT_SIZE\"] = str(1 * 1024 * 1024 * 1024)  # 1GB\n",
    "os.environ[\"MLFLOW_HTTP_REQUEST_TIMEOUT\"] = \"600\"  # 10 minutes\n",
    "os.environ[\"MLFLOW_TCP_KEEPALIVE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9eb2bba-9882-4cbd-af7e-cb3f69903cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 00:48:29 INFO mlflow.tracking.fluent: Experiment with name 'HuggingFaceTB' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model 'HuggingFaceTB/SmolLM2-135M-Instruct' successfully saved and logged as artifacts in MLflow!\n",
      "🧪 Experiment: HuggingFaceTB\n",
      "📌 Run Name: SmolLM2-135M-Instruct\n",
      "🔗 Run ID: ea8a642cc39d4d70a72376c2a44f9108\n",
      "🏃 View run SmolLM2-135M-Instruct at: http://localhost:5000/#/experiments/3/runs/ea8a642cc39d4d70a72376c2a44f9108\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "# Define Experiment Name (Matching Hugging Face Model Name)\n",
    "EXPERIMENT_NAME = 'HuggingFaceTB'\n",
    "RUN_NAME = 'SmolLM2-135M-Instruct'\n",
    "\n",
    "# Create (or Get) Experiment in MLflow\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # Log Model Directory as Artifacts\n",
    "    mlflow.log_artifacts(MODEL_DIR)\n",
    "\n",
    "    print(f\"✅ Model '{HF_MODEL_NAME}' successfully saved and logged as artifacts in MLflow!\")\n",
    "    print(f\"🧪 Experiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"📌 Run Name: {RUN_NAME}\")\n",
    "    print(f\"🔗 Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f162a25e-3fa1-4db1-8290-8d8d259ccedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf SmolLM2-135M-Instruct/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1aedfe-b7b8-42c0-8224-510443620a5f",
   "metadata": {},
   "source": [
    "## Download model from MLflow (verification that everything is working fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d5ab022-695c-4769-9640-763c9efc6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Latest Run ID: ea8a642cc39d4d70a72376c2a44f9108\n",
      "📂 Artifact: config.json\n",
      "📂 Artifact: generation_config.json\n",
      "📂 Artifact: merges.txt\n",
      "📂 Artifact: model.safetensors\n",
      "📂 Artifact: special_tokens_map.json\n",
      "📂 Artifact: tokenizer.json\n",
      "📂 Artifact: tokenizer_config.json\n",
      "📂 Artifact: vocab.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Define MLflow Run & Artifact Path\n",
    "EXPERIMENT_NAME = 'HuggingFaceTB'\n",
    "DEST_PATH = 'SmolLM2-135M-Instruct'\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "runs = client.search_runs(experiment.experiment_id, order_by=[\"start_time desc\"])\n",
    "\n",
    "if not runs:\n",
    "    raise ValueError(\"No runs found for experiment 'SmolLM2-360M-Instruct'\")\n",
    "\n",
    "latest_run_id = runs[0].info.run_id\n",
    "print(f\"🔗 Latest Run ID: {latest_run_id}\")\n",
    "\n",
    "# List artifacts in this run\n",
    "artifacts = client.list_artifacts(latest_run_id)\n",
    "for artifact in artifacts:\n",
    "    print(f\"📂 Artifact: {artifact.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb51dea3-c8fd-4cb0-88ae-8fb6702bbfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a4b5749d584106b0d602a4b76ab152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model downloaded to: /root/madrigal/src/SmolLM2-135M-Instruct/\n"
     ]
    }
   ],
   "source": [
    "MODEL_DOWNLOAD_PATH = mlflow.artifacts.download_artifacts(run_id=latest_run_id, dst_path=DEST_PATH)\n",
    "print(f\"✅ Model downloaded to: {MODEL_DOWNLOAD_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a5326-a3ee-45f7-bc3b-f20554ed6518",
   "metadata": {},
   "source": [
    "## Load and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1d1e603-905e-4b40-92b0-5cc730d338ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Model Response: system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
      "user\n",
      "What is gravity?\n",
      "assistant\n",
      "Gravity is a fundamental force of nature that attracts objects with mass towards each other. It is a\n"
     ]
    }
   ],
   "source": [
    "# Load Model & Tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_DOWNLOAD_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DOWNLOAD_PATH)\n",
    "\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Encode Input Without System Instructions\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Response\n",
    "outputs = model.generate(inputs, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"🤖 Model Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b20c3b22-593f-4f2e-a9fa-5cfe3cfca956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf SmolLM2-135M-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19328f33-1180-4fcd-8555-aca92e800ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
