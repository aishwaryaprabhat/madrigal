{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a74160",
   "metadata": {},
   "source": [
    "# Interactive Distributed Red Teaming\n",
    "\n",
    "- This notebook demonstrates how to perform distributed Red Teaming using garak + Ray + MLFlow.\n",
    "- A version of this code, with tweaks to transform it into a Kubeflow pipeine, is available in [distrt_pipeline.py](distrt_pipeline.py).\n",
    "- [](kfp_launcher.ipynb) then takes the [distrt_pipeline.py](distrt_pipeline.py), transforms it into a [kfp yaml](madrigal_pipeline.yaml) file and submits it to Kubeflow to run.\n",
    "\n",
    "### Prerequisites\n",
    "1. A running KubeRay cluster that you can connect to with `ray://localhost:10001` or your own Ray instance.\n",
    "2. An MLflow server to track experiment data (`MLFLOW_ADDRESS`).\n",
    "\n",
    "### Usage\n",
    "1. Adjust the `RAY_CLUSTER_ADDRESS` and `MLFLOW_ADDRESS` constants to match your environment.\n",
    "2. Run each cell in sequence.\n",
    "3. Ray will parallelize the execution of Garak probes.\n",
    "4. Artifacts and logs from Garak runs will be uploaded to MLflow.\n",
    "5. At the end, a combined JSONL file and an HTML report (`final_report.html`) will be generated locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f2d6c",
   "metadata": {},
   "source": [
    "## 1. Environment Initialization\n",
    "In the next cell, we:\n",
    "- Configure Ray to connect to the running cluster.\n",
    "- Specify environment variables for MLflow.\n",
    "- Shut down any existing Ray instance and re-initialize with the new settings.\n",
    "Make sure to update `RAY_CLUSTER_ADDRESS` and `MLFLOW_ADDRESS` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae6058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os \n",
    "\n",
    "RAY_CLUSTER_ADDRESS = \"ray://localhost:10001\"  # exposed using kubectl -n raycluster port-forward svc/raycluster-kuberay-head-svc 10001 &\n",
    "MLFLOW_ADDRESS = 'http://mlflow-tracking.mlflow.svc'\n",
    "\n",
    "os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\"\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        address=RAY_CLUSTER_ADDRESS,\n",
    "        log_to_driver=False,\n",
    "        runtime_env={\n",
    "            \"pip\": [\"torch\", \"transformers\", \"garak\", \"mlflow\"],\n",
    "            \"env_vars\": {\n",
    "                'MLFLOW_TRACKING_URI': MLFLOW_ADDRESS\n",
    "            },\n",
    "            \"working_dir\": \".\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b800c60",
   "metadata": {},
   "source": [
    "## 2. Imports and Helper Functions\n",
    "Here, we:\n",
    "- Import `garak`, `mlflow`, and other necessary libraries.\n",
    "- (Optionally) reload the `custom_generator` module.\n",
    "- Define a helper function `combine_jsonl_from_dir` to combine multiple Garak report outputs into a single JSONL file.\n",
    "- Define a Ray-remote function `run_probe` which:\n",
    "  1. Runs Garak's CLI to probe a custom model.\n",
    "  2. Logs artifacts to MLflow.\n",
    "- Define a Ray-remote function `run_red_teaming` which:\n",
    "  1. Starts an MLflow run.\n",
    "  2. Distributes multiple probes using Ray.\n",
    "  3. Downloads artifacts and combines them into a single JSONL.\n",
    "  4. Creates an HTML digest of the final results and logs it to MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8063ba-164d-47f8-8287-c48bc1fc1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "import ray\n",
    "import mlflow\n",
    "\n",
    "import garak\n",
    "import garak.cli\n",
    "from garak.command import write_report_digest\n",
    "from garak.report import Report\n",
    "\n",
    "import custom_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a88c0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload custom_generator to ensure any dynamic code changes are captured\n",
    "importlib.reload(custom_generator)\n",
    "\n",
    "\n",
    "def combine_jsonl_from_dir(directory: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Combine multiple JSONL files from a given directory into a single output file.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory containing the .jsonl files to combine.\n",
    "        output_file (str): The path to the consolidated JSONL file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect all files with the suffix \"report.jsonl\" from the directory\n",
    "    jsonl_files = [\n",
    "        f for f in os.listdir(directory) \n",
    "        if f.endswith(\"report.jsonl\")\n",
    "    ]\n",
    "    # Convert to absolute paths\n",
    "    jsonl_files = [os.path.join(directory, f) for f in jsonl_files]\n",
    "\n",
    "    if not jsonl_files:\n",
    "        print(\"‚ö†Ô∏è No JSONL files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for file_path in jsonl_files:\n",
    "            with open(file_path, \"r\") as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()\n",
    "                    \n",
    "                    # Skip empty lines\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    # Validate JSON. If valid, write it to the output file.\n",
    "                    try:\n",
    "                        json.loads(line)\n",
    "                        outfile.write(line + \"\\n\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"‚ùå Skipping malformed JSON in {file_path}: {e} ‚Üí {line}\")\n",
    "\n",
    "    print(f\"‚úÖ Combined {len(jsonl_files)} JSONL files into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736b099-c644-43aa-8fb0-6fdd78ee4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@ray.remote\n",
    "def run_probe(probe_name: str, mlflow_runid: str) -> None:\n",
    "    \"\"\"\n",
    "    Execute a single Garak probe using a custom model, then log the artifacts to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        probe_name (str): Name of the probe to run.\n",
    "        mlflow_runid (str): Existing MLflow run ID to which the artifacts are logged.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Make this parametrizable if needed\n",
    "    garak_runs_dir = \"/home/ray/.local/share/garak/garak_runs/\"\n",
    "\n",
    "    # Optionally remove old runs before the new run (commented out by default):\n",
    "    # for item in os.scandir(garak_runs_dir):\n",
    "    #     (shutil.rmtree if item.is_dir() else os.unlink)(item.path)\n",
    "\n",
    "    # Construct CLI command\n",
    "    cli_command = (\n",
    "        \"--parallel_requests 1 \"\n",
    "        \"--model_type function \"\n",
    "        \"--model_name custom_generator#generate_response \"\n",
    "        \"--probes {probe_name}\"\n",
    "    )\n",
    "    cli_command = cli_command.format(probe_name=probe_name)\n",
    "\n",
    "    # Run Garak CLI\n",
    "    garak.cli.main(cli_command.split())\n",
    "\n",
    "    # Log artifacts to the shared MLflow run\n",
    "    with mlflow.start_run(run_id=mlflow_runid):\n",
    "        mlflow.log_artifacts(garak_runs_dir)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def run_red_teaming(probes_list: list) -> None:\n",
    "    \"\"\"\n",
    "    Run red teaming tests on a list of probes in parallel using Ray and log artifacts to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        probes_list (list): A list of probe names to run.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create or use an existing experiment named \"garak_runs\"\n",
    "    mlflow.set_experiment(\"garak_runs\")\n",
    "\n",
    "    # Start a new MLflow run\n",
    "    with mlflow.start_run(run_name=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")) as mlflow_run:\n",
    "        mlflow_runid = mlflow_run.info.run_id\n",
    "        print(f\"üìù MLflow Run ID: {mlflow_runid}\")\n",
    "\n",
    "        # Kick off Ray tasks to run each probe in parallel, passing the shared MLflow run ID\n",
    "        futures = [run_probe.remote(probe_name, mlflow_runid) for probe_name in probes_list]\n",
    "        ray.get(futures)  # Wait for all tasks to complete\n",
    "\n",
    "        # Download artifacts produced by each probe run into a local directory\n",
    "        mlflow.artifacts.download_artifacts(run_id=mlflow_runid, dst_path=\"./combined_logs\")\n",
    "\n",
    "        # Combine the resulting JSONL files for further processing/reporting\n",
    "        combine_jsonl_from_dir(\"./combined_logs\", \"combined_logs.jsonl\")\n",
    "\n",
    "        # Generate an HTML report from the combined logs\n",
    "        write_report_digest(\"combined_logs.jsonl\", \"./final_report.html\")\n",
    "        \n",
    "        # For debugging: see current directory contents\n",
    "        print(os.listdir())\n",
    "        \n",
    "        print(\"HTML contents written to final_report.html\")\n",
    "\n",
    "        # Log the final HTML report to MLflow\n",
    "        mlflow.log_artifact(\"./final_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635f566",
   "metadata": {},
   "source": [
    "## 3. Running the Red Teaming Probes\n",
    "In this cell, we specify a list of probe names (e.g., `grandma.Substances`, `grandma.Slurs`, etc.) and call the `run_red_teaming` function asynchronously using `Ray`.\n",
    "\n",
    "Once the probes complete, their output is combined into a single JSONL file, and an HTML report (`final_report.html`) is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4227b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = run_red_teaming.remote(['grandma.Substances', 'grandma.Slurs', 'grandma.Win10', 'lmrc.Bullying', 'lmrc.Profanity'])\n",
    "ray.get(runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
