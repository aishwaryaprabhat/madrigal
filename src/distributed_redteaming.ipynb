{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a74160",
   "metadata": {},
   "source": [
    "# Garak-based Red Teaming Notebook\n",
    "\n",
    "This notebook demonstrates how to use [Garak](https://github.com/chatsim/garak) to run red-teaming probes against a custom text generation model.\n",
    "\n",
    "## Overview\n",
    "- **Ray** is used for distributed execution.\n",
    "- **MLflow** is used for experiment tracking.\n",
    "- **Garak** is used to generate and run probes.\n",
    "\n",
    "### Prerequisites\n",
    "1. A running Ray cluster that you can connect to with `ray://localhost:10001` or your own Ray instance.\n",
    "2. An MLflow server to track experiment data (`MLFLOW_ADDRESS`).\n",
    "3. The Python packages required by `runtime_env` (such as `torch`, `transformers`, `garak`, `mlflow`).\n",
    "\n",
    "### Usage\n",
    "1. Adjust the `RAY_CLUSTER_ADDRESS` and `MLFLOW_ADDRESS` constants to match your environment.\n",
    "2. Run each cell in sequence.\n",
    "3. Ray will parallelize the execution of Garak probes.\n",
    "4. Artifacts and logs from Garak runs will be uploaded to MLflow.\n",
    "5. At the end, a combined JSONL file and an HTML report (`final_report.html`) will be generated locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f2d6c",
   "metadata": {},
   "source": [
    "## 1. Environment Initialization\n",
    "In the next cell, we:\n",
    "- Configure Ray to connect to the running cluster.\n",
    "- Specify environment variables for MLflow.\n",
    "- Shut down any existing Ray instance and re-initialize with the new settings.\n",
    "Make sure to update `RAY_CLUSTER_ADDRESS` and `MLFLOW_ADDRESS` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae6058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os \n",
    "\n",
    "RAY_CLUSTER_ADDRESS = \"ray://localhost:10001\"  # exposed using kubectl -n raycluster port-forward svc/raycluster-kuberay-head-svc 10001 &\n",
    "MLFLOW_ADDRESS = 'http://mlflow-tracking.mlflow.svc'\n",
    "\n",
    "os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\"\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "ray.init(\n",
    "        address=RAY_CLUSTER_ADDRESS,\n",
    "        log_to_driver=False,\n",
    "        runtime_env={\n",
    "            \"pip\": [\"torch\", \"transformers\", \"garak\", \"mlflow\"],\n",
    "            \"env_vars\": {\n",
    "                'MLFLOW_TRACKING_URI': MLFLOW_ADDRESS\n",
    "            },\n",
    "            \"working_dir\": \".\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b800c60",
   "metadata": {},
   "source": [
    "## 2. Imports and Helper Functions\n",
    "Here, we:\n",
    "- Import `garak`, `mlflow`, and other necessary libraries.\n",
    "- (Optionally) reload the `custom_generator` module.\n",
    "- Define a helper function `combine_jsonl_from_dir` to combine multiple Garak report outputs into a single JSONL file.\n",
    "- Define a Ray-remote function `run_probe` which:\n",
    "  1. Runs Garak's CLI to probe a custom model.\n",
    "  2. Logs artifacts to MLflow.\n",
    "- Define a Ray-remote function `run_red_teaming` which:\n",
    "  1. Starts an MLflow run.\n",
    "  2. Distributes multiple probes using Ray.\n",
    "  3. Downloads artifacts and combines them into a single JSONL.\n",
    "  4. Creates an HTML digest of the final results and logs it to MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a88c0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import garak\n",
    "import garak.cli\n",
    "from garak.report import Report\n",
    "import custom_generator\n",
    "import importlib\n",
    "from garak.command import write_report_digest\n",
    "import mlflow\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "importlib.reload(custom_generator)\n",
    "\n",
    "\n",
    "def combine_jsonl_from_dir(directory, output_file):\n",
    "    jsonl_files = [f for f in os.listdir(directory) if f.endswith(\"report.jsonl\")]  # Get all JSONL files\n",
    "    jsonl_files = [os.path.join(directory, f) for f in jsonl_files]  # Full file paths\n",
    "\n",
    "    if not jsonl_files:\n",
    "        print(\"‚ö†Ô∏è No JSONL files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for file in jsonl_files:\n",
    "            with open(file, \"r\") as infile:\n",
    "                for line in infile:\n",
    "                    line = line.strip()  # Remove extra whitespace\n",
    "                    \n",
    "                    if not line:  # Ignore empty lines\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        json.loads(line)  # Validate JSON\n",
    "                        outfile.write(line + \"\\n\")  # Ensure each JSON object is on a separate line\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"‚ùå Skipping malformed JSON in {file}: {e} ‚Üí {line}\")\n",
    "\n",
    "    print(f\"‚úÖ Combined {len(jsonl_files)} JSONL files into {output_file}\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def run_probe(probe_name, mlflow_runid):\n",
    "\n",
    "    garak_runs_dir = '/home/ray/.local/share/garak/garak_runs/' #ToDo: find a way to parametrise this\n",
    "    \n",
    "    # Optionally, you could remove old runs here:\n",
    "    # for item in os.scandir(garak_runs_dir):\n",
    "    #     (shutil.rmtree if item.is_dir() else os.unlink)(item.path)\n",
    "    \n",
    "    cli_command = '--parallel_requests 1 --model_type function --model_name custom_generator#generate_response --probes {probe_name} '\n",
    "    cli_command = cli_command.format(probe_name=probe_name)\n",
    "    garak.cli.main(cli_command.split())\n",
    "    \n",
    "    with mlflow.start_run(run_id=mlflow_runid):  # Use shared MLflow run ID\n",
    "        mlflow.log_artifacts(garak_runs_dir) \n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def run_red_teaming(probes_list):\n",
    "    mlflow.set_experiment(\"garak_runs\")\n",
    "    with mlflow.start_run(run_name=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")) as run:\n",
    "        mlflow_runid = run.info.run_id  # Get the Run ID to share across Ray workers\n",
    "        print(f\"üìù MLflow Run ID: {mlflow_runid}\")\n",
    "        \n",
    "        futures = [run_probe.remote(probe_name, mlflow_runid) for probe_name in probes_list]\n",
    "        results = ray.get(futures)\n",
    "        \n",
    "        mlflow.artifacts.download_artifacts(run_id=mlflow_runid, dst_path='./combined_logs')  \n",
    "        combine_jsonl_from_dir('./combined_logs', 'combined_logs.jsonl')\n",
    "        \n",
    "        write_report_digest('combined_logs.jsonl', './final_report.html')\n",
    "        print(os.listdir())\n",
    "        print(\"HTML contents writtten to final_report.html\")\n",
    "        mlflow.log_artifact('./final_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635f566",
   "metadata": {},
   "source": [
    "## 3. Running the Red Teaming Probes\n",
    "In this cell, we specify a list of probe names (e.g., `grandma.Substances`, `grandma.Slurs`, etc.) and call the `run_red_teaming` function asynchronously using `Ray`.\n",
    "\n",
    "Once the probes complete, their output is combined into a single JSONL file, and an HTML report (`final_report.html`) is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4227b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = run_red_teaming.remote(['grandma.Substances', 'grandma.Slurs', 'grandma.Win10', 'lmrc.Bullying', 'lmrc.Profanity'])\n",
    "ray.get(runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
